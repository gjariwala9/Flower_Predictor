{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop('species', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(4, activation='relu', input_shape=[4,]))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.0901 - accuracy: 0.3667 - val_loss: 1.1254 - val_accuracy: 0.3667\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0811 - accuracy: 0.3583 - val_loss: 1.1165 - val_accuracy: 0.3667\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0726 - accuracy: 0.3583 - val_loss: 1.1077 - val_accuracy: 0.3667\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0642 - accuracy: 0.3583 - val_loss: 1.0996 - val_accuracy: 0.3667\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0562 - accuracy: 0.3583 - val_loss: 1.0916 - val_accuracy: 0.3333\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0481 - accuracy: 0.3583 - val_loss: 1.0839 - val_accuracy: 0.3667\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0407 - accuracy: 0.3667 - val_loss: 1.0764 - val_accuracy: 0.3667\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0334 - accuracy: 0.3750 - val_loss: 1.0690 - val_accuracy: 0.3667\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0265 - accuracy: 0.3750 - val_loss: 1.0620 - val_accuracy: 0.3667\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0193 - accuracy: 0.3750 - val_loss: 1.0552 - val_accuracy: 0.3667\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0127 - accuracy: 0.3917 - val_loss: 1.0487 - val_accuracy: 0.4000\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0064 - accuracy: 0.4167 - val_loss: 1.0422 - val_accuracy: 0.4000\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0000 - accuracy: 0.4250 - val_loss: 1.0359 - val_accuracy: 0.4000\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9937 - accuracy: 0.4833 - val_loss: 1.0299 - val_accuracy: 0.4000\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9877 - accuracy: 0.5583 - val_loss: 1.0239 - val_accuracy: 0.4333\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9818 - accuracy: 0.6167 - val_loss: 1.0180 - val_accuracy: 0.4667\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9759 - accuracy: 0.6500 - val_loss: 1.0123 - val_accuracy: 0.5000\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9701 - accuracy: 0.6583 - val_loss: 1.0067 - val_accuracy: 0.5000\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9644 - accuracy: 0.6667 - val_loss: 1.0013 - val_accuracy: 0.5333\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9588 - accuracy: 0.6667 - val_loss: 0.9960 - val_accuracy: 0.5667\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9532 - accuracy: 0.6833 - val_loss: 0.9911 - val_accuracy: 0.5667\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9477 - accuracy: 0.6833 - val_loss: 0.9861 - val_accuracy: 0.5667\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9422 - accuracy: 0.6833 - val_loss: 0.9814 - val_accuracy: 0.5667\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9368 - accuracy: 0.6833 - val_loss: 0.9766 - val_accuracy: 0.5667\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9314 - accuracy: 0.6833 - val_loss: 0.9720 - val_accuracy: 0.5667\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9262 - accuracy: 0.6833 - val_loss: 0.9675 - val_accuracy: 0.5667\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9210 - accuracy: 0.6833 - val_loss: 0.9629 - val_accuracy: 0.5667\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9160 - accuracy: 0.6833 - val_loss: 0.9583 - val_accuracy: 0.5667\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9108 - accuracy: 0.6833 - val_loss: 0.9540 - val_accuracy: 0.5667\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9059 - accuracy: 0.6833 - val_loss: 0.9497 - val_accuracy: 0.5667\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9010 - accuracy: 0.6833 - val_loss: 0.9455 - val_accuracy: 0.5667\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8962 - accuracy: 0.6833 - val_loss: 0.9412 - val_accuracy: 0.5667\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8915 - accuracy: 0.6833 - val_loss: 0.9371 - val_accuracy: 0.5667\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8866 - accuracy: 0.6833 - val_loss: 0.9327 - val_accuracy: 0.5667\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8822 - accuracy: 0.6833 - val_loss: 0.9287 - val_accuracy: 0.5667\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8773 - accuracy: 0.6833 - val_loss: 0.9243 - val_accuracy: 0.5667\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8727 - accuracy: 0.6833 - val_loss: 0.9201 - val_accuracy: 0.5667\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8684 - accuracy: 0.6917 - val_loss: 0.9160 - val_accuracy: 0.5667\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8640 - accuracy: 0.6917 - val_loss: 0.9119 - val_accuracy: 0.5667\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8600 - accuracy: 0.6917 - val_loss: 0.9078 - val_accuracy: 0.5667\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8556 - accuracy: 0.6917 - val_loss: 0.9040 - val_accuracy: 0.5667\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8515 - accuracy: 0.6917 - val_loss: 0.9001 - val_accuracy: 0.5667\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8474 - accuracy: 0.6917 - val_loss: 0.8963 - val_accuracy: 0.5667\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8432 - accuracy: 0.6917 - val_loss: 0.8924 - val_accuracy: 0.5667\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8390 - accuracy: 0.6917 - val_loss: 0.8886 - val_accuracy: 0.5667\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8349 - accuracy: 0.6917 - val_loss: 0.8847 - val_accuracy: 0.5667\n",
      "Epoch 47/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8307 - accuracy: 0.6917 - val_loss: 0.8807 - val_accuracy: 0.5667\n",
      "Epoch 48/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8265 - accuracy: 0.6917 - val_loss: 0.8770 - val_accuracy: 0.5667\n",
      "Epoch 49/300\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.8224 - accuracy: 0.6917 - val_loss: 0.8730 - val_accuracy: 0.6000\n",
      "Epoch 50/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8183 - accuracy: 0.6917 - val_loss: 0.8691 - val_accuracy: 0.6000\n",
      "Epoch 51/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8141 - accuracy: 0.6917 - val_loss: 0.8651 - val_accuracy: 0.6000\n",
      "Epoch 52/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8099 - accuracy: 0.6917 - val_loss: 0.8612 - val_accuracy: 0.6000\n",
      "Epoch 53/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8058 - accuracy: 0.6917 - val_loss: 0.8575 - val_accuracy: 0.6000\n",
      "Epoch 54/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8017 - accuracy: 0.6917 - val_loss: 0.8537 - val_accuracy: 0.6000\n",
      "Epoch 55/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7976 - accuracy: 0.6917 - val_loss: 0.8498 - val_accuracy: 0.6000\n",
      "Epoch 56/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7934 - accuracy: 0.6917 - val_loss: 0.8461 - val_accuracy: 0.6000\n",
      "Epoch 57/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7893 - accuracy: 0.6917 - val_loss: 0.8421 - val_accuracy: 0.6000\n",
      "Epoch 58/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7854 - accuracy: 0.6917 - val_loss: 0.8384 - val_accuracy: 0.6000\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7811 - accuracy: 0.6917 - val_loss: 0.8346 - val_accuracy: 0.6000\n",
      "Epoch 60/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7771 - accuracy: 0.6917 - val_loss: 0.8309 - val_accuracy: 0.6000\n",
      "Epoch 61/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7730 - accuracy: 0.6917 - val_loss: 0.8268 - val_accuracy: 0.6000\n",
      "Epoch 62/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7690 - accuracy: 0.6917 - val_loss: 0.8229 - val_accuracy: 0.6333\n",
      "Epoch 63/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7650 - accuracy: 0.6917 - val_loss: 0.8189 - val_accuracy: 0.6333\n",
      "Epoch 64/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7609 - accuracy: 0.6917 - val_loss: 0.8151 - val_accuracy: 0.6333\n",
      "Epoch 65/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7569 - accuracy: 0.6917 - val_loss: 0.8113 - val_accuracy: 0.6333\n",
      "Epoch 66/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.7531 - accuracy: 0.7000 - val_loss: 0.8073 - val_accuracy: 0.6333\n",
      "Epoch 67/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7491 - accuracy: 0.7000 - val_loss: 0.8038 - val_accuracy: 0.6333\n",
      "Epoch 68/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7451 - accuracy: 0.7000 - val_loss: 0.7999 - val_accuracy: 0.6333\n",
      "Epoch 69/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7412 - accuracy: 0.7000 - val_loss: 0.7962 - val_accuracy: 0.6333\n",
      "Epoch 70/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7373 - accuracy: 0.7000 - val_loss: 0.7925 - val_accuracy: 0.6333\n",
      "Epoch 71/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7333 - accuracy: 0.7000 - val_loss: 0.7891 - val_accuracy: 0.6333\n",
      "Epoch 72/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7295 - accuracy: 0.7000 - val_loss: 0.7853 - val_accuracy: 0.6333\n",
      "Epoch 73/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7257 - accuracy: 0.7000 - val_loss: 0.7815 - val_accuracy: 0.6333\n",
      "Epoch 74/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7220 - accuracy: 0.7083 - val_loss: 0.7776 - val_accuracy: 0.6333\n",
      "Epoch 75/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7181 - accuracy: 0.7083 - val_loss: 0.7743 - val_accuracy: 0.6333\n",
      "Epoch 76/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7143 - accuracy: 0.7167 - val_loss: 0.7707 - val_accuracy: 0.6333\n",
      "Epoch 77/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7105 - accuracy: 0.7167 - val_loss: 0.7670 - val_accuracy: 0.6333\n",
      "Epoch 78/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7068 - accuracy: 0.7167 - val_loss: 0.7635 - val_accuracy: 0.6333\n",
      "Epoch 79/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7030 - accuracy: 0.7167 - val_loss: 0.7600 - val_accuracy: 0.6333\n",
      "Epoch 80/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6994 - accuracy: 0.7167 - val_loss: 0.7566 - val_accuracy: 0.6333\n",
      "Epoch 81/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6957 - accuracy: 0.7167 - val_loss: 0.7529 - val_accuracy: 0.6333\n",
      "Epoch 82/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6921 - accuracy: 0.7167 - val_loss: 0.7493 - val_accuracy: 0.6333\n",
      "Epoch 83/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6886 - accuracy: 0.7167 - val_loss: 0.7463 - val_accuracy: 0.6333\n",
      "Epoch 84/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6849 - accuracy: 0.7167 - val_loss: 0.7429 - val_accuracy: 0.6333\n",
      "Epoch 85/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6813 - accuracy: 0.7167 - val_loss: 0.7394 - val_accuracy: 0.6333\n",
      "Epoch 86/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6778 - accuracy: 0.7167 - val_loss: 0.7360 - val_accuracy: 0.6333\n",
      "Epoch 87/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6743 - accuracy: 0.7167 - val_loss: 0.7326 - val_accuracy: 0.6333\n",
      "Epoch 88/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6708 - accuracy: 0.7167 - val_loss: 0.7292 - val_accuracy: 0.6333\n",
      "Epoch 89/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6673 - accuracy: 0.7167 - val_loss: 0.7258 - val_accuracy: 0.6333\n",
      "Epoch 90/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6640 - accuracy: 0.7167 - val_loss: 0.7224 - val_accuracy: 0.6667\n",
      "Epoch 91/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6605 - accuracy: 0.7167 - val_loss: 0.7192 - val_accuracy: 0.6667\n",
      "Epoch 92/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6571 - accuracy: 0.7167 - val_loss: 0.7158 - val_accuracy: 0.6667\n",
      "Epoch 93/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6538 - accuracy: 0.7167 - val_loss: 0.7126 - val_accuracy: 0.6667\n",
      "Epoch 94/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6505 - accuracy: 0.7250 - val_loss: 0.7092 - val_accuracy: 0.6667\n",
      "Epoch 95/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6472 - accuracy: 0.7250 - val_loss: 0.7060 - val_accuracy: 0.6667\n",
      "Epoch 96/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6440 - accuracy: 0.7333 - val_loss: 0.7026 - val_accuracy: 0.6667\n",
      "Epoch 97/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6406 - accuracy: 0.7417 - val_loss: 0.6992 - val_accuracy: 0.6667\n",
      "Epoch 98/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6375 - accuracy: 0.7500 - val_loss: 0.6960 - val_accuracy: 0.6667\n",
      "Epoch 99/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6343 - accuracy: 0.7500 - val_loss: 0.6927 - val_accuracy: 0.6667\n",
      "Epoch 100/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6312 - accuracy: 0.7500 - val_loss: 0.6895 - val_accuracy: 0.6667\n",
      "Epoch 101/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6281 - accuracy: 0.7500 - val_loss: 0.6865 - val_accuracy: 0.6667\n",
      "Epoch 102/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6250 - accuracy: 0.7500 - val_loss: 0.6832 - val_accuracy: 0.6667\n",
      "Epoch 103/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6221 - accuracy: 0.7500 - val_loss: 0.6800 - val_accuracy: 0.6667\n",
      "Epoch 104/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6189 - accuracy: 0.7500 - val_loss: 0.6773 - val_accuracy: 0.6667\n",
      "Epoch 105/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6160 - accuracy: 0.7500 - val_loss: 0.6743 - val_accuracy: 0.6667\n",
      "Epoch 106/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6130 - accuracy: 0.7500 - val_loss: 0.6716 - val_accuracy: 0.6667\n",
      "Epoch 107/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6100 - accuracy: 0.7500 - val_loss: 0.6690 - val_accuracy: 0.6667\n",
      "Epoch 108/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6070 - accuracy: 0.7500 - val_loss: 0.6661 - val_accuracy: 0.6667\n",
      "Epoch 109/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6042 - accuracy: 0.7500 - val_loss: 0.6636 - val_accuracy: 0.6667\n",
      "Epoch 110/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6013 - accuracy: 0.7500 - val_loss: 0.6608 - val_accuracy: 0.6667\n",
      "Epoch 111/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5984 - accuracy: 0.7500 - val_loss: 0.6578 - val_accuracy: 0.7000\n",
      "Epoch 112/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5956 - accuracy: 0.7500 - val_loss: 0.6550 - val_accuracy: 0.7000\n",
      "Epoch 113/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5929 - accuracy: 0.7500 - val_loss: 0.6519 - val_accuracy: 0.7000\n",
      "Epoch 114/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5900 - accuracy: 0.7500 - val_loss: 0.6492 - val_accuracy: 0.7000\n",
      "Epoch 115/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5873 - accuracy: 0.7500 - val_loss: 0.6464 - val_accuracy: 0.7333\n",
      "Epoch 116/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5846 - accuracy: 0.7500 - val_loss: 0.6435 - val_accuracy: 0.7333\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5819 - accuracy: 0.7500 - val_loss: 0.6408 - val_accuracy: 0.7333\n",
      "Epoch 118/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5792 - accuracy: 0.7500 - val_loss: 0.6381 - val_accuracy: 0.7333\n",
      "Epoch 119/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5766 - accuracy: 0.7500 - val_loss: 0.6356 - val_accuracy: 0.7333\n",
      "Epoch 120/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5741 - accuracy: 0.7500 - val_loss: 0.6327 - val_accuracy: 0.7333\n",
      "Epoch 121/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5714 - accuracy: 0.7500 - val_loss: 0.6303 - val_accuracy: 0.7333\n",
      "Epoch 122/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5688 - accuracy: 0.7500 - val_loss: 0.6276 - val_accuracy: 0.7333\n",
      "Epoch 123/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5662 - accuracy: 0.7583 - val_loss: 0.6251 - val_accuracy: 0.7333\n",
      "Epoch 124/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5638 - accuracy: 0.7583 - val_loss: 0.6226 - val_accuracy: 0.7333\n",
      "Epoch 125/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5613 - accuracy: 0.7583 - val_loss: 0.6201 - val_accuracy: 0.7333\n",
      "Epoch 126/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5588 - accuracy: 0.7583 - val_loss: 0.6175 - val_accuracy: 0.7333\n",
      "Epoch 127/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5563 - accuracy: 0.7667 - val_loss: 0.6151 - val_accuracy: 0.7333\n",
      "Epoch 128/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5540 - accuracy: 0.7667 - val_loss: 0.6129 - val_accuracy: 0.7333\n",
      "Epoch 129/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5515 - accuracy: 0.7667 - val_loss: 0.6105 - val_accuracy: 0.7333\n",
      "Epoch 130/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5492 - accuracy: 0.7750 - val_loss: 0.6080 - val_accuracy: 0.7333\n",
      "Epoch 131/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5468 - accuracy: 0.7750 - val_loss: 0.6056 - val_accuracy: 0.7333\n",
      "Epoch 132/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5445 - accuracy: 0.7750 - val_loss: 0.6033 - val_accuracy: 0.7333\n",
      "Epoch 133/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5422 - accuracy: 0.7750 - val_loss: 0.6008 - val_accuracy: 0.7333\n",
      "Epoch 134/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5401 - accuracy: 0.7750 - val_loss: 0.5980 - val_accuracy: 0.7333\n",
      "Epoch 135/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5376 - accuracy: 0.7750 - val_loss: 0.5958 - val_accuracy: 0.7333\n",
      "Epoch 136/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5354 - accuracy: 0.7833 - val_loss: 0.5936 - val_accuracy: 0.7333\n",
      "Epoch 137/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5332 - accuracy: 0.7917 - val_loss: 0.5913 - val_accuracy: 0.7333\n",
      "Epoch 138/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5310 - accuracy: 0.7917 - val_loss: 0.5891 - val_accuracy: 0.7333\n",
      "Epoch 139/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5288 - accuracy: 0.8000 - val_loss: 0.5867 - val_accuracy: 0.7333\n",
      "Epoch 140/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5266 - accuracy: 0.8000 - val_loss: 0.5846 - val_accuracy: 0.7333\n",
      "Epoch 141/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5246 - accuracy: 0.8000 - val_loss: 0.5821 - val_accuracy: 0.7333\n",
      "Epoch 142/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5224 - accuracy: 0.8000 - val_loss: 0.5801 - val_accuracy: 0.7333\n",
      "Epoch 143/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5203 - accuracy: 0.8000 - val_loss: 0.5781 - val_accuracy: 0.7333\n",
      "Epoch 144/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5182 - accuracy: 0.8000 - val_loss: 0.5759 - val_accuracy: 0.7333\n",
      "Epoch 145/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5163 - accuracy: 0.8083 - val_loss: 0.5734 - val_accuracy: 0.7333\n",
      "Epoch 146/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5141 - accuracy: 0.8250 - val_loss: 0.5714 - val_accuracy: 0.7333\n",
      "Epoch 147/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5120 - accuracy: 0.8250 - val_loss: 0.5695 - val_accuracy: 0.7333\n",
      "Epoch 148/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5100 - accuracy: 0.8333 - val_loss: 0.5674 - val_accuracy: 0.7333\n",
      "Epoch 149/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5080 - accuracy: 0.8333 - val_loss: 0.5655 - val_accuracy: 0.7333\n",
      "Epoch 150/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5061 - accuracy: 0.8333 - val_loss: 0.5638 - val_accuracy: 0.7333\n",
      "Epoch 151/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5040 - accuracy: 0.8333 - val_loss: 0.5616 - val_accuracy: 0.7667\n",
      "Epoch 152/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5021 - accuracy: 0.8333 - val_loss: 0.5596 - val_accuracy: 0.8000\n",
      "Epoch 153/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5001 - accuracy: 0.8333 - val_loss: 0.5576 - val_accuracy: 0.8333\n",
      "Epoch 154/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4983 - accuracy: 0.8333 - val_loss: 0.5554 - val_accuracy: 0.8333\n",
      "Epoch 155/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4964 - accuracy: 0.8333 - val_loss: 0.5534 - val_accuracy: 0.8333\n",
      "Epoch 156/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4945 - accuracy: 0.8333 - val_loss: 0.5515 - val_accuracy: 0.8333\n",
      "Epoch 157/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4926 - accuracy: 0.8333 - val_loss: 0.5495 - val_accuracy: 0.8333\n",
      "Epoch 158/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4909 - accuracy: 0.8333 - val_loss: 0.5472 - val_accuracy: 0.8333\n",
      "Epoch 159/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4889 - accuracy: 0.8333 - val_loss: 0.5453 - val_accuracy: 0.8333\n",
      "Epoch 160/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4871 - accuracy: 0.8333 - val_loss: 0.5435 - val_accuracy: 0.8333\n",
      "Epoch 161/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4853 - accuracy: 0.8333 - val_loss: 0.5417 - val_accuracy: 0.8333\n",
      "Epoch 162/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4835 - accuracy: 0.8333 - val_loss: 0.5400 - val_accuracy: 0.8333\n",
      "Epoch 163/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4817 - accuracy: 0.8417 - val_loss: 0.5380 - val_accuracy: 0.8333\n",
      "Epoch 164/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4800 - accuracy: 0.8417 - val_loss: 0.5361 - val_accuracy: 0.8333\n",
      "Epoch 165/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4782 - accuracy: 0.8417 - val_loss: 0.5341 - val_accuracy: 0.8333\n",
      "Epoch 166/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4764 - accuracy: 0.8417 - val_loss: 0.5324 - val_accuracy: 0.8333\n",
      "Epoch 167/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4748 - accuracy: 0.8417 - val_loss: 0.5307 - val_accuracy: 0.8333\n",
      "Epoch 168/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4730 - accuracy: 0.8417 - val_loss: 0.5289 - val_accuracy: 0.8667\n",
      "Epoch 169/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4714 - accuracy: 0.8417 - val_loss: 0.5272 - val_accuracy: 0.8667\n",
      "Epoch 170/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4696 - accuracy: 0.8417 - val_loss: 0.5254 - val_accuracy: 0.8667\n",
      "Epoch 171/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4679 - accuracy: 0.8417 - val_loss: 0.5236 - val_accuracy: 0.8667\n",
      "Epoch 172/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4663 - accuracy: 0.8417 - val_loss: 0.5219 - val_accuracy: 0.8667\n",
      "Epoch 173/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4646 - accuracy: 0.8417 - val_loss: 0.5202 - val_accuracy: 0.8667\n",
      "Epoch 174/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4630 - accuracy: 0.8417 - val_loss: 0.5187 - val_accuracy: 0.8667\n",
      "Epoch 175/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4613 - accuracy: 0.8417 - val_loss: 0.5167 - val_accuracy: 0.8667\n",
      "Epoch 176/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4598 - accuracy: 0.8417 - val_loss: 0.5147 - val_accuracy: 0.9000\n",
      "Epoch 177/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4582 - accuracy: 0.8417 - val_loss: 0.5132 - val_accuracy: 0.9000\n",
      "Epoch 178/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4565 - accuracy: 0.8417 - val_loss: 0.5113 - val_accuracy: 0.9000\n",
      "Epoch 179/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4549 - accuracy: 0.8417 - val_loss: 0.5096 - val_accuracy: 0.9000\n",
      "Epoch 180/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4533 - accuracy: 0.8417 - val_loss: 0.5078 - val_accuracy: 0.9000\n",
      "Epoch 181/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4517 - accuracy: 0.8417 - val_loss: 0.5059 - val_accuracy: 0.8667\n",
      "Epoch 182/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4502 - accuracy: 0.8500 - val_loss: 0.5041 - val_accuracy: 0.8667\n",
      "Epoch 183/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4487 - accuracy: 0.8500 - val_loss: 0.5027 - val_accuracy: 0.8667\n",
      "Epoch 184/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4471 - accuracy: 0.8500 - val_loss: 0.5007 - val_accuracy: 0.8667\n",
      "Epoch 185/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4455 - accuracy: 0.8500 - val_loss: 0.4991 - val_accuracy: 0.8667\n",
      "Epoch 186/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4441 - accuracy: 0.8500 - val_loss: 0.4973 - val_accuracy: 0.8667\n",
      "Epoch 187/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4425 - accuracy: 0.8500 - val_loss: 0.4958 - val_accuracy: 0.8667\n",
      "Epoch 188/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4410 - accuracy: 0.8500 - val_loss: 0.4942 - val_accuracy: 0.8667\n",
      "Epoch 189/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4395 - accuracy: 0.8500 - val_loss: 0.4925 - val_accuracy: 0.8667\n",
      "Epoch 190/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4381 - accuracy: 0.8583 - val_loss: 0.4908 - val_accuracy: 0.8667\n",
      "Epoch 191/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4365 - accuracy: 0.8667 - val_loss: 0.4894 - val_accuracy: 0.8667\n",
      "Epoch 192/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4351 - accuracy: 0.8750 - val_loss: 0.4880 - val_accuracy: 0.8667\n",
      "Epoch 193/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4336 - accuracy: 0.8583 - val_loss: 0.4864 - val_accuracy: 0.8667\n",
      "Epoch 194/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4322 - accuracy: 0.8750 - val_loss: 0.4848 - val_accuracy: 0.8667\n",
      "Epoch 195/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4308 - accuracy: 0.8750 - val_loss: 0.4831 - val_accuracy: 0.8667\n",
      "Epoch 196/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4293 - accuracy: 0.8750 - val_loss: 0.4816 - val_accuracy: 0.8667\n",
      "Epoch 197/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4279 - accuracy: 0.8750 - val_loss: 0.4803 - val_accuracy: 0.8667\n",
      "Epoch 198/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4265 - accuracy: 0.8750 - val_loss: 0.4785 - val_accuracy: 0.8667\n",
      "Epoch 199/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4250 - accuracy: 0.8750 - val_loss: 0.4769 - val_accuracy: 0.8667\n",
      "Epoch 200/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4238 - accuracy: 0.8833 - val_loss: 0.4751 - val_accuracy: 0.8667\n",
      "Epoch 201/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4224 - accuracy: 0.8833 - val_loss: 0.4739 - val_accuracy: 0.8667\n",
      "Epoch 202/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4209 - accuracy: 0.8833 - val_loss: 0.4724 - val_accuracy: 0.8667\n",
      "Epoch 203/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4195 - accuracy: 0.8833 - val_loss: 0.4709 - val_accuracy: 0.8667\n",
      "Epoch 204/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4183 - accuracy: 0.8833 - val_loss: 0.4691 - val_accuracy: 0.8667\n",
      "Epoch 205/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4168 - accuracy: 0.8833 - val_loss: 0.4675 - val_accuracy: 0.8667\n",
      "Epoch 206/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4156 - accuracy: 0.8833 - val_loss: 0.4658 - val_accuracy: 0.8667\n",
      "Epoch 207/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4141 - accuracy: 0.8833 - val_loss: 0.4645 - val_accuracy: 0.8667\n",
      "Epoch 208/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4127 - accuracy: 0.8833 - val_loss: 0.4633 - val_accuracy: 0.8667\n",
      "Epoch 209/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4114 - accuracy: 0.8833 - val_loss: 0.4620 - val_accuracy: 0.8667\n",
      "Epoch 210/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4101 - accuracy: 0.8833 - val_loss: 0.4609 - val_accuracy: 0.8667\n",
      "Epoch 211/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4087 - accuracy: 0.8833 - val_loss: 0.4596 - val_accuracy: 0.8667\n",
      "Epoch 212/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4075 - accuracy: 0.8833 - val_loss: 0.4582 - val_accuracy: 0.8667\n",
      "Epoch 213/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4061 - accuracy: 0.8833 - val_loss: 0.4568 - val_accuracy: 0.8667\n",
      "Epoch 214/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4049 - accuracy: 0.8833 - val_loss: 0.4555 - val_accuracy: 0.8667\n",
      "Epoch 215/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4036 - accuracy: 0.8833 - val_loss: 0.4541 - val_accuracy: 0.8667\n",
      "Epoch 216/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4023 - accuracy: 0.8833 - val_loss: 0.4527 - val_accuracy: 0.8667\n",
      "Epoch 217/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4010 - accuracy: 0.8917 - val_loss: 0.4514 - val_accuracy: 0.8667\n",
      "Epoch 218/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3997 - accuracy: 0.8917 - val_loss: 0.4499 - val_accuracy: 0.8667\n",
      "Epoch 219/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3985 - accuracy: 0.9000 - val_loss: 0.4484 - val_accuracy: 0.8667\n",
      "Epoch 220/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3972 - accuracy: 0.9000 - val_loss: 0.4471 - val_accuracy: 0.8667\n",
      "Epoch 221/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3960 - accuracy: 0.9000 - val_loss: 0.4456 - val_accuracy: 0.9000\n",
      "Epoch 222/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3947 - accuracy: 0.9000 - val_loss: 0.4442 - val_accuracy: 0.9000\n",
      "Epoch 223/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3935 - accuracy: 0.9000 - val_loss: 0.4427 - val_accuracy: 0.9000\n",
      "Epoch 224/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3924 - accuracy: 0.9083 - val_loss: 0.4412 - val_accuracy: 0.9000\n",
      "Epoch 225/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3909 - accuracy: 0.9083 - val_loss: 0.4400 - val_accuracy: 0.9000\n",
      "Epoch 226/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3897 - accuracy: 0.9083 - val_loss: 0.4389 - val_accuracy: 0.9000\n",
      "Epoch 227/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3886 - accuracy: 0.9083 - val_loss: 0.4377 - val_accuracy: 0.9000\n",
      "Epoch 228/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3874 - accuracy: 0.9083 - val_loss: 0.4366 - val_accuracy: 0.9000\n",
      "Epoch 229/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3863 - accuracy: 0.9083 - val_loss: 0.4350 - val_accuracy: 0.9000\n",
      "Epoch 230/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3849 - accuracy: 0.9083 - val_loss: 0.4336 - val_accuracy: 0.9000\n",
      "Epoch 231/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3838 - accuracy: 0.9083 - val_loss: 0.4322 - val_accuracy: 0.9000\n",
      "Epoch 232/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3825 - accuracy: 0.9167 - val_loss: 0.4309 - val_accuracy: 0.9000\n",
      "Epoch 233/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3813 - accuracy: 0.9167 - val_loss: 0.4296 - val_accuracy: 0.9000\n",
      "Epoch 234/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3802 - accuracy: 0.9167 - val_loss: 0.4282 - val_accuracy: 0.9000\n",
      "Epoch 235/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3791 - accuracy: 0.9167 - val_loss: 0.4272 - val_accuracy: 0.9000\n",
      "Epoch 236/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3778 - accuracy: 0.9167 - val_loss: 0.4260 - val_accuracy: 0.9000\n",
      "Epoch 237/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3766 - accuracy: 0.9167 - val_loss: 0.4247 - val_accuracy: 0.9333\n",
      "Epoch 238/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3754 - accuracy: 0.9167 - val_loss: 0.4232 - val_accuracy: 0.9333\n",
      "Epoch 239/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3742 - accuracy: 0.9167 - val_loss: 0.4219 - val_accuracy: 0.9333\n",
      "Epoch 240/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3732 - accuracy: 0.9167 - val_loss: 0.4207 - val_accuracy: 0.9333\n",
      "Epoch 241/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3720 - accuracy: 0.9167 - val_loss: 0.4194 - val_accuracy: 0.9333\n",
      "Epoch 242/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3708 - accuracy: 0.9250 - val_loss: 0.4179 - val_accuracy: 0.9333\n",
      "Epoch 243/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3697 - accuracy: 0.9250 - val_loss: 0.4164 - val_accuracy: 0.9333\n",
      "Epoch 244/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3686 - accuracy: 0.9167 - val_loss: 0.4150 - val_accuracy: 0.9333\n",
      "Epoch 245/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3676 - accuracy: 0.9167 - val_loss: 0.4138 - val_accuracy: 0.9333\n",
      "Epoch 246/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3663 - accuracy: 0.9167 - val_loss: 0.4127 - val_accuracy: 0.9333\n",
      "Epoch 247/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3652 - accuracy: 0.9167 - val_loss: 0.4116 - val_accuracy: 0.9333\n",
      "Epoch 248/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3640 - accuracy: 0.9167 - val_loss: 0.4105 - val_accuracy: 0.9333\n",
      "Epoch 249/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3629 - accuracy: 0.9167 - val_loss: 0.4093 - val_accuracy: 0.9333\n",
      "Epoch 250/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3618 - accuracy: 0.9167 - val_loss: 0.4082 - val_accuracy: 0.9333\n",
      "Epoch 251/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3608 - accuracy: 0.9250 - val_loss: 0.4070 - val_accuracy: 0.9333\n",
      "Epoch 252/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3596 - accuracy: 0.9250 - val_loss: 0.4060 - val_accuracy: 0.9333\n",
      "Epoch 253/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3587 - accuracy: 0.9250 - val_loss: 0.4051 - val_accuracy: 0.9333\n",
      "Epoch 254/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3575 - accuracy: 0.9250 - val_loss: 0.4038 - val_accuracy: 0.9333\n",
      "Epoch 255/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3564 - accuracy: 0.9250 - val_loss: 0.4025 - val_accuracy: 0.9333\n",
      "Epoch 256/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3555 - accuracy: 0.9250 - val_loss: 0.4015 - val_accuracy: 0.9333\n",
      "Epoch 257/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3544 - accuracy: 0.9250 - val_loss: 0.4001 - val_accuracy: 0.9333\n",
      "Epoch 258/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3532 - accuracy: 0.9250 - val_loss: 0.3989 - val_accuracy: 0.9333\n",
      "Epoch 259/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3521 - accuracy: 0.9167 - val_loss: 0.3977 - val_accuracy: 0.9333\n",
      "Epoch 260/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3511 - accuracy: 0.9167 - val_loss: 0.3965 - val_accuracy: 0.9333\n",
      "Epoch 261/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3501 - accuracy: 0.9250 - val_loss: 0.3954 - val_accuracy: 0.9333\n",
      "Epoch 262/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3490 - accuracy: 0.9167 - val_loss: 0.3942 - val_accuracy: 0.9333\n",
      "Epoch 263/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3479 - accuracy: 0.9250 - val_loss: 0.3931 - val_accuracy: 0.9333\n",
      "Epoch 264/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3469 - accuracy: 0.9250 - val_loss: 0.3919 - val_accuracy: 0.9333\n",
      "Epoch 265/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3458 - accuracy: 0.9333 - val_loss: 0.3907 - val_accuracy: 0.9667\n",
      "Epoch 266/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3448 - accuracy: 0.9333 - val_loss: 0.3895 - val_accuracy: 0.9667\n",
      "Epoch 267/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3438 - accuracy: 0.9417 - val_loss: 0.3883 - val_accuracy: 0.9667\n",
      "Epoch 268/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3429 - accuracy: 0.9417 - val_loss: 0.3871 - val_accuracy: 0.9667\n",
      "Epoch 269/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3417 - accuracy: 0.9417 - val_loss: 0.3861 - val_accuracy: 0.9667\n",
      "Epoch 270/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3407 - accuracy: 0.9417 - val_loss: 0.3852 - val_accuracy: 0.9333\n",
      "Epoch 271/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3397 - accuracy: 0.9333 - val_loss: 0.3843 - val_accuracy: 0.9333\n",
      "Epoch 272/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3388 - accuracy: 0.9333 - val_loss: 0.3833 - val_accuracy: 0.9333\n",
      "Epoch 273/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3377 - accuracy: 0.9417 - val_loss: 0.3821 - val_accuracy: 0.9333\n",
      "Epoch 274/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3367 - accuracy: 0.9333 - val_loss: 0.3809 - val_accuracy: 0.9333\n",
      "Epoch 275/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3357 - accuracy: 0.9333 - val_loss: 0.3798 - val_accuracy: 0.9333\n",
      "Epoch 276/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3347 - accuracy: 0.9333 - val_loss: 0.3787 - val_accuracy: 0.9333\n",
      "Epoch 277/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3337 - accuracy: 0.9417 - val_loss: 0.3776 - val_accuracy: 0.9333\n",
      "Epoch 278/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3327 - accuracy: 0.9333 - val_loss: 0.3766 - val_accuracy: 0.9333\n",
      "Epoch 279/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3317 - accuracy: 0.9333 - val_loss: 0.3755 - val_accuracy: 0.9333\n",
      "Epoch 280/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3308 - accuracy: 0.9333 - val_loss: 0.3745 - val_accuracy: 0.9333\n",
      "Epoch 281/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3297 - accuracy: 0.9417 - val_loss: 0.3734 - val_accuracy: 0.9667\n",
      "Epoch 282/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3288 - accuracy: 0.9417 - val_loss: 0.3723 - val_accuracy: 0.9667\n",
      "Epoch 283/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3278 - accuracy: 0.9417 - val_loss: 0.3711 - val_accuracy: 0.9667\n",
      "Epoch 284/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3268 - accuracy: 0.9583 - val_loss: 0.3699 - val_accuracy: 0.9667\n",
      "Epoch 285/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3258 - accuracy: 0.9583 - val_loss: 0.3688 - val_accuracy: 0.9667\n",
      "Epoch 286/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3250 - accuracy: 0.9583 - val_loss: 0.3677 - val_accuracy: 0.9667\n",
      "Epoch 287/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3239 - accuracy: 0.9583 - val_loss: 0.3667 - val_accuracy: 0.9667\n",
      "Epoch 288/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3230 - accuracy: 0.9583 - val_loss: 0.3657 - val_accuracy: 0.9667\n",
      "Epoch 289/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3220 - accuracy: 0.9583 - val_loss: 0.3647 - val_accuracy: 0.9667\n",
      "Epoch 290/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3211 - accuracy: 0.9583 - val_loss: 0.3638 - val_accuracy: 0.9667\n",
      "Epoch 291/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3201 - accuracy: 0.9583 - val_loss: 0.3627 - val_accuracy: 0.9667\n",
      "Epoch 292/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3191 - accuracy: 0.9583 - val_loss: 0.3616 - val_accuracy: 0.9667\n",
      "Epoch 293/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3182 - accuracy: 0.9583 - val_loss: 0.3606 - val_accuracy: 0.9667\n",
      "Epoch 294/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3173 - accuracy: 0.9583 - val_loss: 0.3596 - val_accuracy: 0.9667\n",
      "Epoch 295/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3163 - accuracy: 0.9583 - val_loss: 0.3586 - val_accuracy: 0.9667\n",
      "Epoch 296/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3154 - accuracy: 0.9583 - val_loss: 0.3576 - val_accuracy: 0.9667\n",
      "Epoch 297/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3145 - accuracy: 0.9583 - val_loss: 0.3566 - val_accuracy: 0.9667\n",
      "Epoch 298/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3136 - accuracy: 0.9583 - val_loss: 0.3556 - val_accuracy: 0.9667\n",
      "Epoch 299/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3127 - accuracy: 0.9583 - val_loss: 0.3547 - val_accuracy: 0.9667\n",
      "Epoch 300/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3118 - accuracy: 0.9583 - val_loss: 0.3538 - val_accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a34e51e320>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X_train, y_train, epochs=300, validation_data=(scaled_X_test, y_test), callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a3a28e37f0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2a39a3734e0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3537554442882538, 0.9666666388511658]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test,y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for label setosa:\n",
      "[[20  0]\n",
      " [ 0 10]]\n",
      "Confusion matrix for label versicolor:\n",
      "[[17  1]\n",
      " [ 1 11]]\n",
      "Confusion matrix for label virginica:\n",
      "[[22  0]\n",
      " [ 1  7]]\n"
     ]
    }
   ],
   "source": [
    "labels = ['setosa', 'versicolor', 'virginica']\n",
    "\n",
    "conf_mat_dict={}\n",
    "\n",
    "for label_col in range(len(labels)):\n",
    "    y_test_label = y_test[:, label_col]\n",
    "    y_pred_label = y_pred[:, label_col]\n",
    "    conf_mat_dict[labels[label_col]] = confusion_matrix(y_pred=y_pred_label, y_true=y_test_label)\n",
    "\n",
    "\n",
    "for label, matrix in conf_mat_dict.items():\n",
    "    print(\"Confusion matrix for label {}:\".format(label))\n",
    "    print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       0.92      0.92      0.92        12\n",
      "           2       1.00      0.88      0.93         8\n",
      "\n",
      "   micro avg       0.97      0.93      0.95        30\n",
      "   macro avg       0.97      0.93      0.95        30\n",
      "weighted avg       0.97      0.93      0.95        30\n",
      " samples avg       0.93      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = len(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(4, activation='relu', input_shape=[4,]))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.1227 - accuracy: 0.3200\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1153 - accuracy: 0.3267\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1080 - accuracy: 0.3333\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.1009 - accuracy: 0.3333\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0937 - accuracy: 0.3333\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0873 - accuracy: 0.3333\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0806 - accuracy: 0.3333\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0740 - accuracy: 0.3333\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0680 - accuracy: 0.3333\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0622 - accuracy: 0.3467\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0562 - accuracy: 0.6267\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0505 - accuracy: 0.6667\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0451 - accuracy: 0.6667\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0399 - accuracy: 0.6600\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0349 - accuracy: 0.6533\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0302 - accuracy: 0.6533\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0255 - accuracy: 0.6533\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0210 - accuracy: 0.6533\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 1.0162 - accuracy: 0.6533\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0118 - accuracy: 0.6533\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0072 - accuracy: 0.6533\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 1.0029 - accuracy: 0.6533\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9983 - accuracy: 0.6533\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9939 - accuracy: 0.6533\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9894 - accuracy: 0.6533\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9849 - accuracy: 0.6533\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9806 - accuracy: 0.6533\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9762 - accuracy: 0.6600\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9718 - accuracy: 0.6600\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9675 - accuracy: 0.6600\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9631 - accuracy: 0.6667\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9587 - accuracy: 0.6667\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9544 - accuracy: 0.6667\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9500 - accuracy: 0.6800\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9457 - accuracy: 0.6800\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9414 - accuracy: 0.6800\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9370 - accuracy: 0.6933\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9326 - accuracy: 0.6933\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9283 - accuracy: 0.6933\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.9239 - accuracy: 0.6933\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9195 - accuracy: 0.7000\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9152 - accuracy: 0.7067\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.9108 - accuracy: 0.7067\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9063 - accuracy: 0.7067\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.9019 - accuracy: 0.7067\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8974 - accuracy: 0.7067\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8930 - accuracy: 0.7133\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8888 - accuracy: 0.7067\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8841 - accuracy: 0.7133\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8796 - accuracy: 0.7200\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8752 - accuracy: 0.7200\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8707 - accuracy: 0.7200\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8662 - accuracy: 0.7267\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8617 - accuracy: 0.7267\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8571 - accuracy: 0.7200\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8527 - accuracy: 0.7200\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8479 - accuracy: 0.7200\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8434 - accuracy: 0.7200\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8387 - accuracy: 0.7200\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.8343 - accuracy: 0.7133\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8296 - accuracy: 0.7133\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8249 - accuracy: 0.7133\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8203 - accuracy: 0.7133\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8157 - accuracy: 0.7133\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8111 - accuracy: 0.7133\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8065 - accuracy: 0.7067\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.8018 - accuracy: 0.7067\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7972 - accuracy: 0.7067\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7925 - accuracy: 0.7067\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7878 - accuracy: 0.7067\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7832 - accuracy: 0.7067\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7786 - accuracy: 0.7067\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7740 - accuracy: 0.7067\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7695 - accuracy: 0.7067\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7649 - accuracy: 0.7067\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7602 - accuracy: 0.7067\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7556 - accuracy: 0.7067\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7511 - accuracy: 0.7067\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7466 - accuracy: 0.7067\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7421 - accuracy: 0.7067\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7376 - accuracy: 0.7000\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7331 - accuracy: 0.7000\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7288 - accuracy: 0.7000\n",
      "Epoch 84/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7243 - accuracy: 0.7000\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.7200 - accuracy: 0.7000\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7155 - accuracy: 0.7000\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7112 - accuracy: 0.7000\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7070 - accuracy: 0.7000\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.7027 - accuracy: 0.7000\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6985 - accuracy: 0.7000\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6944 - accuracy: 0.7000\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6903 - accuracy: 0.7000\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.7000\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.7000\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6781 - accuracy: 0.7000\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6742 - accuracy: 0.7000\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6702 - accuracy: 0.7000\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6664 - accuracy: 0.7000\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.7000\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.7000\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.7000\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6513 - accuracy: 0.7067\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.7067\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6440 - accuracy: 0.7067\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.7067\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.7067\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.7067\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6300 - accuracy: 0.7067\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6265 - accuracy: 0.7067\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.7067\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.7067\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6165 - accuracy: 0.7067\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6134 - accuracy: 0.7067\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6101 - accuracy: 0.7067\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6070 - accuracy: 0.7067\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6039 - accuracy: 0.7067\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.6008 - accuracy: 0.7067\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5977 - accuracy: 0.7067\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5947 - accuracy: 0.7067\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.7067\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5889 - accuracy: 0.7067\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5860 - accuracy: 0.7067\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.7067\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7067\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.7067\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5749 - accuracy: 0.7067\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7067\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5696 - accuracy: 0.7067\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5669 - accuracy: 0.7133\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7133\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5618 - accuracy: 0.7133\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7133\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7267\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7267\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5520 - accuracy: 0.7267\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5496 - accuracy: 0.7267\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7333\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7333\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7333\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7333\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7333\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7333\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7333\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7333\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7333\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7333\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7333\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7333\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5215 - accuracy: 0.7400\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7400\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7400\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.7400\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.7400\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7400\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.7400\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.5549 - accuracy: 0.71 - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7400\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7400\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.7400\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7400\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5015 - accuracy: 0.7467\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7467\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7467\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7467\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7467\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7467\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7533\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.7533\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7600\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7600\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7667\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7667\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7667\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.7733\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7733\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.7733\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.7733\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.7733\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.7800\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.7800\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7800\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7867\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7867\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7933\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7933\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.8000\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.8000\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.8000\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.8000\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.8067\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.8067\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.8067\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.8067\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.8067\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.8133\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.8133\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.8133\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.8133\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.8133\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4487 - accuracy: 0.8133\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4477 - accuracy: 0.8133\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.8200\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4454 - accuracy: 0.8200\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8200\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4432 - accuracy: 0.8267\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4421 - accuracy: 0.8333\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4410 - accuracy: 0.8333\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8333\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8333\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4376 - accuracy: 0.8333\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8333\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.8333\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.8333\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.8333\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.8333\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.8333\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8333\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8333\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8400\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8600\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8667\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.8667\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8667\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4210 - accuracy: 0.8667\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4197 - accuracy: 0.8667\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4184 - accuracy: 0.8733\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8733\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.8733\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8733\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8733\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8800\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8933\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8933\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8933\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8933\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.9000\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.9000\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4028 - accuracy: 0.9000\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.9133\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.9133\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.9133\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3975 - accuracy: 0.9133\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.9133\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.9133\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.9333\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.9333\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3908 - accuracy: 0.9333\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3895 - accuracy: 0.9333\n",
      "Epoch 248/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.9400\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.9467\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3855 - accuracy: 0.9467\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.9467\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.9467\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3815 - accuracy: 0.9467\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.9533\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3789 - accuracy: 0.9600\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.9667\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.9667\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.9667\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.9667\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.9667\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.9667\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.9667\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.9667\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.9667\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.9667\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.9667\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.9667\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3618 - accuracy: 0.9667\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.9667\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3593 - accuracy: 0.9667\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3581 - accuracy: 0.9667\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3568 - accuracy: 0.9667\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3555 - accuracy: 0.9667\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.9667\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.9667\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.9667\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3505 - accuracy: 0.9667\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3492 - accuracy: 0.9667\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.9667\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3467 - accuracy: 0.9667\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3454 - accuracy: 0.9667\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.9667\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.9667\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3418 - accuracy: 0.9667\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3405 - accuracy: 0.9667\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3393 - accuracy: 0.9667\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.9667\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3368 - accuracy: 0.9667\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.9667\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.9667\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.9667\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.9667\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.9667\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3294 - accuracy: 0.9667\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3282 - accuracy: 0.9667\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.9667\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.9667\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.9667\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 1.00 - 0s 2ms/step - loss: 0.3235 - accuracy: 0.9667\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a3a7d40550>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X, y, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_model = load_model('final_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_scaler = joblib.load('scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example ={'sepal_length': 5.1,\n",
    "                'sepal_width': 3.5,\n",
    "                'petal_length': 1.4,\n",
    "                'petal_width': 0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prediction(model, scaler, sample_json):\n",
    "    s_len = sample_json['sepal_length']\n",
    "    s_wid = sample_json['sepal_width']\n",
    "    p_len = sample_json['petal_length']\n",
    "    p_wid = sample_json['petal_width']\n",
    "    \n",
    "    flower = [[s_len, s_wid, p_len, p_wid]]\n",
    "    \n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    class_ind = model.predict_classes(flower)[0]\n",
    "    \n",
    "    return classes[class_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-46-54d9b9acceec>:13: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_prediction(flower_model,flower_scaler, flower_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE FOR DEPLOYMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "flower_model = load_model('final_model.h5')\n",
    "\n",
    "flower_scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "def return_prediction(model, scaler, sample_json):\n",
    "    s_len = sample_json['sepal_length']\n",
    "    s_wid = sample_json['sepal_width']\n",
    "    p_len = sample_json['petal_length']\n",
    "    p_wid = sample_json['petal_width']\n",
    "    \n",
    "    flower = [[s_len, s_wid, p_len, p_wid]]\n",
    "    \n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    class_ind = model.predict_classes(flower)[0]\n",
    "    \n",
    "    return classes[class_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
